{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Part-3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohitag14/NLP-Project-Delta/blob/main/Part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC-ow7GU3Pmt",
        "trusted": true,
        "outputId": "a8682a1b-58b6-47a9-cd53-e4b8ab555ba8"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/kaggle/working\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ULiBXwh0LU2",
        "trusted": true
      },
      "source": [
        "! wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
        "! unzip stanford-corenlp-full-2018-10-05.zip\n",
        "! pip install stanfordcorenlp\n",
        "! pip install stanford-openie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppfkQULN3hhK",
        "trusted": true
      },
      "source": [
        "!wget https://github.com/philipperemy/Stanford-OpenIE-Python/tree/master/openie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUxHjV-60MJU",
        "trusted": true
      },
      "source": [
        "#from openie import StanfordOpenIE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMQV2Cr70vdI",
        "trusted": true
      },
      "source": [
        "#os.environ[\"CORENLP_HOME\"]='/root/stanfordnlp_resources/stanford-corenlp-full-2018-10-05'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HavJ1K5r2Ldf",
        "trusted": true
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from subprocess import Popen\n",
        "from sys import stderr\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import wget\n",
        "\n",
        "\n",
        "class StanfordOpenIE:\n",
        "\n",
        "    def __init__(self, core_nlp_version: str = '4.1.0'):\n",
        "        self.install_dir = Path('~/.stanfordnlp_resources/').expanduser()\n",
        "        self.install_dir.mkdir(exist_ok=True)\n",
        "        if len([d for d in self.install_dir.glob('*') if d.is_dir()]) == 0:\n",
        "            # No coreNLP directories. Let's check for ZIP archives as well.\n",
        "            zip_files = [d for d in self.install_dir.glob('*') if d.suffix == '.zip']\n",
        "            if len(zip_files) == 0:\n",
        "                # No dir and no ZIP. Let's download it with the desired core_nlp_version.\n",
        "                remote_url = 'https://nlp.stanford.edu/software/stanford-corenlp-{}.zip'.format(core_nlp_version)\n",
        "                print('Downloading from %s.' % remote_url)\n",
        "                output_filename = wget.download(remote_url, out=str(self.install_dir))\n",
        "                print('\\nExtracting to %s.' % self.install_dir)\n",
        "            else:\n",
        "                output_filename = zip_files[0]\n",
        "            print('Unzip %s.' % output_filename)\n",
        "            zf = ZipFile(output_filename)\n",
        "            zf.extractall(path=self.install_dir)\n",
        "            zf.close()\n",
        "        target_dir = [d for d in self.install_dir.glob('*') if d.is_dir()][0]\n",
        "\n",
        "        os.environ['CORENLP_HOME'] = str(self.install_dir / target_dir)\n",
        "        from stanfordnlp.server import CoreNLPClient\n",
        "        self.client = CoreNLPClient(annotators=['openie'], memory='8G')\n",
        "\n",
        "    def annotate(self, text: str, properties_key: str = None, properties: dict = None, simple_format: bool = True):\n",
        "        \"\"\"\n",
        "        :param (str | unicode) text: raw text for the CoreNLPServer to parse\n",
        "        :param (str) properties_key: key into properties cache for the client\n",
        "        :param (dict) properties: additional request properties (written on top of defaults)\n",
        "        :param (bool) simple_format: whether to return the full format of CoreNLP or a simple dict.\n",
        "        :return: Depending on simple_format: full or simpler format of triples <subject, relation, object>.\n",
        "        \"\"\"\n",
        "        # https://stanfordnlp.github.io/CoreNLP/openie.html\n",
        "        core_nlp_output = self.client.annotate(text=text, annotators=['openie'], output_format='json',\n",
        "                                               properties_key=properties_key, properties=properties)\n",
        "        if simple_format:\n",
        "            triples = []\n",
        "            for sentence in core_nlp_output['sentences']:\n",
        "                for triple in sentence['openie']:\n",
        "                    triples.append({\n",
        "                        'subject': triple['subject'],\n",
        "                        'relation': triple['relation'],\n",
        "                        'object': triple['object']\n",
        "                    })\n",
        "            return triples\n",
        "        else:\n",
        "            return core_nlp_output\n",
        "\n",
        "    def generate_graphviz_graph(self, text: str, png_filename: str = './out/graph.png'):\n",
        "        \"\"\"\n",
        "       :param (str | unicode) text: raw text for the CoreNLPServer to parse\n",
        "       :param (list | string) png_filename: list of annotators to use\n",
        "       \"\"\"\n",
        "        entity_relations = self.annotate(text, simple_format=True)\n",
        "        \"\"\"digraph G {\n",
        "        # a -> b [ label=\"a to b\" ];\n",
        "        # b -> c [ label=\"another label\"];\n",
        "        }\"\"\"\n",
        "        graph = list()\n",
        "        graph.append('digraph {')\n",
        "        for er in entity_relations:\n",
        "            graph.append('\"{}\" -> \"{}\" [ label=\"{}\" ];'.format(er['subject'], er['object'], er['relation']))\n",
        "        graph.append('}')\n",
        "\n",
        "        output_dir = os.path.join('.', os.path.dirname(png_filename))\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        out_dot = os.path.join(tempfile.gettempdir(), 'graph.dot')\n",
        "        with open(out_dot, 'w') as output_file:\n",
        "            output_file.writelines(graph)\n",
        "\n",
        "        command = 'dot -Tpng {} -o {}'.format(out_dot, png_filename)\n",
        "        dot_process = Popen(command, stdout=stderr, shell=True)\n",
        "        dot_process.wait()\n",
        "        assert not dot_process.returncode, 'ERROR: Call to dot exited with a non-zero code status.'\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        pass\n",
        "\n",
        "    def __del__(self):\n",
        "        self.client.stop()\n",
        "        del os.environ['CORENLP_HOME']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv1KDn1W06uV",
        "trusted": true,
        "outputId": "0a6335ab-8227-403e-db32-8948042ffb88"
      },
      "source": [
        "#from openie import StanfordOpenIE\n",
        "with StanfordOpenIE() as client:\n",
        "    text = text1[0:10000]\n",
        "    ##print('Text: %s.' % text)\n",
        "    for triple in client.annotate(text):\n",
        "        print('|-', triple)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting server with command: java -Xmx8G -cp /root/.stanfordnlp_resources/stanford-corenlp-4.1.0/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-0a35d2471cbe4c87.props -preload openie\n",
            "|- {'subject': 'road', 'relation': 'is with', 'object': 'mutinous intent of taking back to blackheath reins'}\n",
            "|- {'subject': 'you', 'relation': 'give away', 'object': 'it'}\n",
            "|- {'subject': 'hundreds', 'relation': 'is in', 'object': 'town viii monseigneur'}\n",
            "|- {'subject': 'anyone', 'relation': 'is with', 'object': 'almost no restrictions whatsoever'}\n",
            "|- {'subject': 'farmer', 'relation': 's', 'object': 'boy of sixpence'}\n",
            "|- {'subject': 'shooter', 'relation': 's', 'object': 'hill'}\n",
            "|- {'subject': 'guard', 'relation': 'is in', 'object': 'combination'}\n",
            "|- {'subject': 'stand', 'relation': 'is with', 'object': 'wary'}\n",
            "|- {'subject': 'city tradesman', 'relation': 'is in', 'object': 'light'}\n",
            "|- {'subject': 'gorgon', 'relation': 's', 'object': 'head'}\n",
            "|- {'subject': 'king', 'relation': 'is with', 'object': 'fair face on throne of france in countries'}\n",
            "|- {'subject': 'common way', 'relation': 'is in', 'object': 'midst of them'}\n",
            "|- {'subject': 'british subjects', 'relation': 'is in', 'object': 'america'}\n",
            "|- {'subject': 'everything', 'relation': 'was', 'object': 'steaming'}\n",
            "|- {'subject': 'fair face', 'relation': 'is in', 'object': 'countries'}\n",
            "|- {'subject': 'fought battles', 'relation': 'is with', 'object': 'their turnkeys'}\n",
            "|- {'subject': 'steaming mist', 'relation': 'is in', 'object': 'hollows'}\n",
            "|- {'subject': 'highwayman', 'relation': 'is in', 'object': 'dark'}\n",
            "|- {'subject': 'mere messages', 'relation': 'is in', 'object': 'earthly order of events'}\n",
            "|- {'subject': 'town viii monseigneur', 'relation': 'is in', 'object': 'country'}\n",
            "|- {'subject': 'you', 'relation': 'give', 'object': 'it'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q8YXMcH9SUrE",
        "outputId": "47646168-91af-41b1-b831-eec067b60442"
      },
      "source": [
        "#from openie import StanfordOpenIE\n",
        "with StanfordOpenIE() as client:\n",
        "    text = text2[0:10000]\n",
        "    ##print('Text: %s.' % text)\n",
        "    for triple in client.annotate(text):\n",
        "        print('|-', triple)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting server with command: java -Xmx8G -cp /root/.stanfordnlp_resources/stanford-corenlp-4.1.0/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-9ebd54d33bf8450c.props -preload openie\n",
            "|- {'subject': 'his design', 'relation': 'is in', 'object': 'settling here design nonsense'}\n",
            "|- {'subject': 'heaven', 'relation': 'for', 'object': 'sake'}\n",
            "|- {'subject': 'anyone', 'relation': 'is with', 'object': 'almost no restrictions whatsoever'}\n",
            "|- {'subject': 'fortnight', 'relation': 's', 'object': 'acquaintance'}\n",
            "|- {'subject': 'single man', 'relation': 'is in', 'object': 'possession of good fortune'}\n",
            "|- {'subject': 'discretion', 'relation': 'is in', 'object': 'her coughs'}\n",
            "|- {'subject': 'his', 'relation': 'name', 'object': 'bingley'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bs78zWWGSUrE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}